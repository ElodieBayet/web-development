
# Docker : Bonnes pratiques

## Sommaire
1. [Construction d'images](#construction-dimages)
1. [En développement](#en-développement)
1. [Sécurité](#sécurité)
1. [Maintenance](#maintenance)
1. [Annexes](#annexes)
    - [Glossaire](#glossaire)
    - [Pour en savoir plus](#pour-en-savoir-plus)

---


## Construction d'images

### Build context

C'est le répertoire où se trouve le `Dockerfile` et tous les fichiers nécessaires à la construction de l'image. Le _Docker Client_ va archiver ce répertoire, l'envoyer au _Docker Engine_ situé soit sur le même host soit sur un serveur distant.

Un fichier `.dockerignore` sert à exclure les fichiers non pertinent de la construction de l'image. 
```Dockerfile
# Exclure tous les fichiers qui commencent par 'proj' situés dans tous les dossiers de ce niveau
*/proj*

# Exclure tous les fichiers qui commencent par 'proj' et suivi d'un seul caractère
proj?

# Exclure tous les fichiers dont l'extension est '.go' dans n'importe quel niveau de répertoires / sous-répertoires
**/*.go

# Exclure tous les fichiers '.md' SAUF les fichiers nommés 'readme.md'
*.md
! readme.md
```


### Dockerfile

Utiliser dès que possible des builds par étapes, ce qui réduira la taille de l'image. Étant donné que l'image est créée au cours de la dernière étape, on pourrait minimiser les couches en tirant parti du cache
```Dockerfile
FROM alphaimage as ONE
RUN 
.../...
# On repart d'une image finale et on copie depuis le résultat de ONE à la racine du répertoire
FROM betafinale
COPY --from=ONE resultat /
```

Utiliser un minium d'instruction de type _Docker_, comme l'instruction `RUN` avec laquelle on va exécuter plusieurs commandes. L'idée est de les placer par ordre alphabéthique pour pouvoir y accéder facilement.
```Dockerfile
RUN yum update && yum install -y \
    bzip \
    cvs \ 
    git \
    mercurial \
    subversion \
    && rm -rf /var/lib/yum/history*
```

Utiliser des labels pour faciliter l'organisation des images par projets, définir les licences, les versions etc.
```dockerfile
LABEL com.organisation.version="1.2.1"
LABEL com.organisation.projet="demeter"
LABEL com.organisation.release-date="2023-21-23"
```

Enfin, éviter d'installer des packages inutiles pour réduire les tailles des images, réduire les dépendances, réduire la complexité et donc réduire le temps de construction.


---


## En développement

### Images

Spécifier la version de l'image à partir de laquelle on part. Car, par défaut, ce sera l'iamge `latest`, or c'est le distributeur qui choisi quelle version est `latest`. Et à la prochaine construction, on risque de briser la compatibilité parceque la version `latest` aura été upgradée.

Préférer les images dites "réduites", `httpd:2.4` est basé sur _Debian_, mais `httpd:2.4-alpine` est basé sur _Alpine_ qui est plus réduite.

L'instruction `CMD` peut exister seule mais uniquement pour les images de base. Cette instruction a deux forme : 
- soit le format _exec_ qui va exécuter la commande comme premier processus dans le conteneur
- soit le format _Shell_ qui va lancer un _Shell_ dans le conteneur qui va exécuter la commande, ce qui est intéressant uniquement si on a des arguments qui ont des _wild cards_ – par ex. `dir *.old` – pour que l'interpréteur interprète les méta-caractères. 
```Dockerfile
# Format exec
CMD ['command', 'arg1', 'arg2']

# Format shell
CMD command arg1 arg2
```

Dans le cas des applications, il faut une instruction `ENTRYPOINT` qui sera, cette fois, le point d'entrée et `CMD` sera simplement les arguments du `ENTRYPOINT`. 

Il faudra également spécifier les ports que l'application doit ouvrir et les exposer via l'instruction `EXPOSE`. Le conteneur de l'application s'exécute dans un réseau _bridge_, d'autres conteneurs sont donc exécutés en parallèle.


### Exécution

Pour une application, il faut également connaitre ses besoins en mémoire et en CPUs.
Définition finie
```sh
docker run --cpus=2 --memory=512m -d nginx
```
Octroyer un ratio aux conteneurs
```sh
docker run --cpu-share=2 nginx
```

Les applications exécutées dans les conteneurs doivent écrire des messages dans les journaux sur la sortie standard et la sortie d'erreurs plutôt que dans des fichiers.
```Dockerfile
# Exemple avec nginx
# ...
RUN ...
# forward request and error logs to docker log collector
    && ln -sf /dev/stdout /var/log/nginx/access.log \
    && ln -sf /dev/stderr /var/log/nginx/error.log \
# ...
```


---


## Sécurité

### Exécution

58% des images exécutent l'`ENTRYPOINT` en tant que `root`. Or, elle ne doit **jamais s'exécuter en tant que `root`**. Il faut créer un _User_ adapté à l'image de base – donc au niveau _Linux_ – et basculer vers ce _User_ avant l'`ENTRYPOINT`.
```Dockerfile
RUN ...
    && useradd -u 1000 -g 1000 elo
# ...
USER elo
# ..
ENTRYPOINT ...
```


### Analyse

Scanner régulièrement les images applicatives et aussi les images de bases en local. Mais aussi maintenir fréquemment le scanner à jour
```sh
docker scan --version
```

Protéger la socket _Docker_ qu'elle soit locale ou distante, en vérifiant la version, le propriétaire et les permissions.
```sh
# elo@host1
ls -l /var/run/docker.sock
```
Si _Docker_ est exposé via _TCP_, ça veut dire que le serveur _Docker_ est accessible à partir du client distant. Le _Docker Daemon_ est donc démarré en mode _TCP_, il faut ainsi s'assurer qu'il soit protégé avec TLS – _Transport Layer Security_, qui remplace _SSL_. 

De manière plus approfondie, il faut aussi eviter de copier les fichiers de configuration, surtout s'ils contiennent des données sensibles, dans le _Dockerfile_. Il est préférable de fournir ces fichiers au moment de lancer le conteneur par la fonction `mount`. On peut aussi sécuriser ces fichiers de configuration en utilisant des outils de secrets, soit des outils Docker, soit des outils d'éditeurs tiers. 

On peut aussi mettre en place des outils de surveillance. La surveillance est un élément essentiel de toute sécurité, de toute stratégie de sécurité. Des outils spécialisés de surveillance existent pour spécifiquement surveiller un environnement _Docker_. 

Au niveau des réseaux privés de _Docker_, il faut utiliser le réseau _host_ que si c'est vraiment nécessaire. Il est fortement recommandé de ne pas s'appuyer sur le réseau _bridge_ par défaut et d'utiliser des réseaux de type `bridge` personnalisés. Ceci afin de contrôler les conteneurs qui peuvent communiquer entre eux, et pour activer la fonction _DNS_ automatique en évitant d'utiliser l'adressage IP. En somme, chaque nouveau projet indépendant doit avoir un nouveau réseau de type `bridge`.


---


## Maintenance

**Nettoyage du système**

Un nettoyage du système entrainera la suppression de : 
- l'ensemble des conteneurs qui ne sont pas en cours d'exécuion
- l'ensemble des réseaux créés par _Docker_ qui ne sont pas utilisés par au moins un conteneur
- l'ensemble des images non utilisées
- l'ensemble des caches utilisés pour la création d'images

```sh
docker system prune
```
