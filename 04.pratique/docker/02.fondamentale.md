
# Docker : Connaissance fondamentale

## Sommaire
1. [Conteneurs](#conteneurs)
    - [Cycle de vie](#cycle-de-vie)
    - [Construction](#construction-et-exécution)
    - [Gestion](#gestion)
1. [Images](#images)
    - [Couches](#couches)
    - [Méthodes statiques](#méthodes-statiques)
    - [Rédaction](#rédaction)
    - [Distribution](#distribution)
1. [Annexes](#annexes)
    - [Glossaire](#glossaire)
    - [Pour en savoir plus](#pour-en-savoir-plus)

---


## Conteneurs

### Cycle de vie

#### Type de conteneurs

Tout conteneur est créé à partir d'une image. Mais il existe deux catégories distinctes selon les besoins 
- type _Job_ : exécution ponctuelle – un peu comme un _Batch_
    - exécuté avec un processus interne, le programme dans le conteneur se termine par un `exit`
    - détruit une fois le processus terminé
    - exemple : sauvegarde quotidienne de serveur, transfert de données, etc.
- type _Service_ / type _Serveur_ : exécution continue
    - exécuté avec un service interne, en continu jusqu'à extinction
    - arrêté et redémarré à la demande
    - interaction possible avec le service
    - exemple : serveur web, serveur de base de données, etc.


### Construction et exécution

La construction et l'exécution se font au moyen de l'instruction gobale `docker run` à laquelle on passe le nom de l'image. Le _Docker Deamon_ va :
- vérifier la présence de l'image dans les installations locales
- si elle n'y est pas, il va la chercher sur le _Docker Hub_ et la télécharger
- créer un conteneur depuis cette image et l'exécuter
- après l'exécution, il va retirer l'image

Construire et lancer un conteneur à partir d'une image officielle du _Docker Hub_
```sh
docker run hello-world
```
À partir d'un registre privé
```sh
docker run --name myapp registry.mycompany.net/project/myapp:latest
```

Mais si un conteneur local s'appelle `hello-world`, le _Docker Deamon_ va simplement l'exécuter.


#### Propriétaire du processus

Par défaut, les conteneurs sont exécutés en tant que `root` puisque ce sont des processus enfants du _Docker Deamon_, et le deamon s'exécute en mode `root`

Construire et lancer un conteneur Ubuntu par défaut – mode root – en affichant le processus
```sh
docker run ubuntu ps aux
```
Ou avec un user de base
```sh
docker run --user=bin ubuntu ps aux
```


#### Mode attaché

Si on souhaite se connecter au niveau d'un conteneur _Ubuntu_ on va utiliser l'option `-t` pour créer un terminal et l'option `-i` pour le rendre interactif. L'entrée-sortie du premier processus sera redirigée vers ce terminal. On spécifie ensuite quel Shell on veut

Mode interactif avec un terminal Bash et un prompt en tant que `root`. Par défaut, l'hôte porte l'id du conteneur
```sh
docker run -ti ubuntu bash
```
En spécifiant un nom pour l'hôte
```sh
docker run -ti --hostname=host42 ubuntu bash
```

De cette manière on est "attaché" au conteneur en cours d'exécution. Si on fait un `CTRL` + `P` + `Q` on se "détache" du conteneur. La commande `docker ps -l` affiche le dernier processus lancé et l'état `STATUS` est `Up XX seconds` au lieu de `Exited (0) X minutes ago`. Ce qui confirme que le conteneur continue de fonctionner.

On peut se "rattacher" à un conteneur si celui a été lancé avec un terminal interactif – `-ti` en spécifiant son nom ou son id SHA
```sh
docker attach container_name
```


#### Mode détaché

Construire et lancer un conteneur serveur en mode 'détaché' en attribuant un nom
```sh
docker run -d --name=web nginx
```
En spécifiant le port
```sh
docker run -d -p 8080:80 nginx
```

Lorsqu'on lance un conteneur en mode détaché, _Docker_ renvoie un ID unique – par ex. `80550cdf8cb0ce9e697fc5cadbb35bc91f906e2fc91bc6570bfc0c6105a0f590` – qui sera nécessaire pour stopper le conteneur.
```sh
docker stop 80550cdf8cb0ce9e697fc5cadbb35bc91f906e2fc91bc6570bfc0c6105a0f590
```


#### Modes usuels

Lorsque les conteneurs sont déjà construits, on peut simplement les démarrer, les arrêter, ou interagir à sa guise. On cible le conteneur en l'appelant par son nom ou par son identifiant SHA-256.

**Mode _fonctionnnement_**

```sh
# Démarrer un conteneur
docker start container_name

# Arrêter proprement un conteneur
docker stop container_name

# Forcer l'arrêt d'un conteneur qui ne répond pas
docker kill container_name
```

Le `kill` est equivalent au `kill -KILL` ou `kill -9` sous _Linux_, le système va retirer brutalement le processus de la mémoire vive.


**Mode _dépannage_**

Pour un conteneur lancé en mode détaché, on peut visualiser la sortie standard – le `stdout` – d'un conteneur
```sh
docker logs container_sha
```
Pour un conteneur lancé en mode détaché avec un terminal interactif
```sh
docker exec -it container_sha sh
/# ps -ef
```

`exec` ne peut être exécuté qu'a des fins de débugage. Sinon, lorsqu'on arrête le conteneur, seul le 1er processus sera arrêter proprement, les sous-processus seront terminés tels un `docker kill`.


#### Remarques

Les images _Linux_ ne contiennent que la partie binaire, il n'y a pas de Kernel. Le Kernel employé est celui l'hôte – _CentOS_, _Ubuntu_, etc. 


### Gestion

Occasionnellement, il est utile de lister et d'observer les conteneurs dont on dispose en local ou sur son _Docker Host_.
```sh
# Les conteneurs en cours d'exécution
docker ps

# Tous les conteneurs, même éteints
docker ps -a

# Mode 'quiet' pour n'afficher que l'id des conteneurs
docker ps -aq
```

Certains conteneurs finissent par devenir inutiles et peuvent être supprimer. En principe on ne peut supprimer que des conteneurs éteints.
```sh
# Supprimer tous les conteneurs éteints
docker container prune

# Supprimer un seul conteneur éteint
docker rm container_name

# Supprimer un conteneur en cours d'exécution par la force
docker rm -f container_name

# Commande dynamique pour supprimer tous les conteneurs par leur id SHA
docker rm -f $(docker ps -aq)
```


#### Intervernir dans l'environnement d'exécution

Un conteneur service de base de donnée requiert certaines variables d'environnement. L'option `-e` – ou `--env` – prend une liste de variables d'environnement.
Exemple : un conteneur de base de données MySQL
```sh
docker run -d mysql # service mysql n'a pas démarré : exited (1)
docker logs container_sha # une des variables d'environnement doit être configurée
docker run -d -e MYSQL_ROOT_PASSWORD=mypwd mysql # assigner un mot de passe
```

Un manière un peu plus complète consiste à créer un fichier qui contient une ou plusieurs variables d'environnement et de le passer en paramètre
```sh
cat db.env
MYSQL_ROOT_PASSWORD=mypwd
docker run -d --env-file=db.env mysql
```

Définir des DNS
```sh
docker run -it --dns=8.8.8.8 --dns=8.8.4.4 --dns-search=dom.com ubuntu
```

Définir un Working directory
```sh
docker run -it --workdir=/home ubuntu
```


---


## Images

### Couches

Une image est une collection de fichiers. Ces fichiers sont stockés dans des systèmes de fichiers, et sont entre autres les binaires de l'application, les fichiers de configuration de l'application ainsi que les librairies utiles à son fonctionnement. 

Une image est composée de plusieurs couches et chaque couche est un système de fichiers qui sera monté dans le conteneur en lecture seulement. Chaque couche représente une brique logiciel qui va se rajouter à la couche inférieure. Les systèmes de fichiers sont fusionnés et le terme utilisé est "un montage en mode merge" ou "en mode union". 

Une image contient aussi une couche de base – généralement de type _Linux_. En somme, une image est constinuée de plusieurs couches et chaque couche ajoute des fichiers par rapport à la couche précédente.


#### Fonctionnement

Les couches, les images sont toujours montés en lecture seule et ne peuvent jamais être modifiées directement par le conteneur pendant son exécution. 
Exemple : la couche _Debian_ qui contient le binaire du système d'exploitaton, puis la couche _Apache_ qui contient le serveur web. 
```
+===============+ ---------------+
|   Couche rw   |                |
+---------------+ ---+           |
|     Apache    |    |           +-- Conteneur
+···············+    +--- Image  |
|     Debian    |    |           |
+===============+ ---+-----------+
| Docker Engine |
+===============+
```

Ces deux couches sont montées en "read-only" et forment l'image complète. Lorsqu'on lance un container à partir de cette image, une dernière couche est créée – un dernier _File System_ est monté – et cette fois-ci en écriture. Toute création ou modification de fichiers dans ce conteneur se font toujours niveau de cette couche.

On utilise un mécanisme de "Copy On Write". Ça veut dire que dans le cas où le conteneur doit modifier un fichier se trouvant dans une couche inférieure qui est en lecture seulle, _Docker_ va d'abord copier le fichier à partir de la couche inférieure vers la couche du conteneur qui est en écriture, puis le conteneur pourra modifier le fichier au niveau de sa couche "read/write".


### Créations

Il existe 3 méthodes de création.

**Création interactive**
Ou "dynamique", on créé un conteneur à partir d'une 1re image, on valide des modifications (ajouter des packages, etc.) – arrêter le conteneur et comiiter les modifications – et générer la nouvelle image.

**Création par archive** 
On importe une image à partir d'une archive ou d'une sauvegarde d'un conteneur.

**Création statique**
On rédige un _Dockerfile_ qui contient une liste d'instructions pour ajouter toutes les couches et les informations supplémentaires à la nouvelle image. Ça permet de versionner l'image et de garder une trace des modifications antérieure.

Habituellement, c'est la méthode statique qui est la plus intéressante.


#### Création interactive

Réalisation à partir d'un conteneur.
Exemple : un conteneur initial _CentOS_, dans lequel on ajoute une librairie
```sh
# Commiter le conteneur avec un nouveau nom et un tag
docker commit a6c1872d40ea mycentos:7

# Observer la différence |e| un conteneur et une image précédente sur laquelle il est basé
docker diff a6c1872d40ea

# Visualiser les couches de l'image
docker history mycentos:7
```


#### Création par archive

Réalisation à partir d'une archive.
Exemple : un conteneur initial _Alpine_ dans lequel on ajoute un module `curl`
```sh
# Démarrer en mode terminal interactif
docker run -it alpine:3.17 
 
# Installer curl
apk add curl

# Quitter
exit
```

L'objectif est "d'exporter" le conteneur sur forme d'archive. Ce sera la sauvegarde de l'arborescence du conteneur
```sh
docker export 302e9b852717 -o alpine-curl.tar
```

```Dockerfile
FROM scratch
ADD alpine-curl.tar
CMD ["/bin/sh"]
```

```sh
docker build -t alpine:curl .
docker history alpine:curl # les couches de l'image archivée
docker history alphine:3.17 # les couches de l'image initiale
```


#### Nom des images

Le _Namespace_ racine – `root` – est réservé à _Docker_ et à toute organisation officielle – par ex. `ubuntu:14.04`

Pour les utilisateurs ou les organisations, toutes les images seront préfixées par un _Username_ créé avec les comptes individuels sur le _Docker Hub_ – par ex. `mycompany/myappl:2.1`.

On peut créer son propre _Registry_, un serveur d'image interne à l'entreprise pour distribuer ses images aux utilisateurs. L'application _Registry_ est fournie par _Docker_ sous forme d'image, à partir de laquelle on peut créer un conteneur et donc un serveur de _Registry_ – par ex. `registry.mycompany.com:5000/myappli`


### Méthodes statiques

#### Dockerfile

Un [_Dockerfile_](https://docs.docker.com/engine/reference/builder/) est un script qui détaille la création d'une image _Docker_ et qui – la plupart du temps – commence depuis une autre image existante. Dans certains cas, il n'est pas nécessaire de créer ses propres images, notamment s'il s'agit de lancer quelques serveurs.

On l'appelle aussi "recette", car chaque instruction dans un `Dockerfile` va créer une _Layer_ correspondant à chaque étape de construction de l'image. À l'instar d'une pièce montée en cuisine, où chaque argument dans le `Dockerfile` correspond à un nouvel "étage" de la pièce montée. Le but étant néanmoins de faire la "pièce montée" la plus légère et performante possible.


#### Contruction et exécution

L'instruction `docker build` sert à construire une image à partir d'un _Dockerfile_. Chaque résultat sera sauvegardé dans une _Layer_ et le résultat final constituera un ensemble de _Layers_ établissant l'image complète.

Exemple : un conteneur initial _CentOS_, dans lequel on ajoute une librairie
```Dockerfile
# Dockerfile
FROM centos:7
RUN yum install wget -y
```

Une bonne pratique consiste à avoir un dossier par projet, et donc un _Dockerfile_ par dossier. On peut ainsi construire l'image en lui attribuant un nom `-t` – pour faciliter la gestion – et en ciblant le répertoire où se situe le `Dockerfile`. 
Construire l'image à partir du dossier du projet
```sh
docker build myproject/ -t mycompany/mycentos:7bis
```
⚠️ Lorsqu'on "build" à partir d'une image officielle, il faut penser à spécifier son nom – et opionnellement un tag `name:tag` – sinon lors d'un éventuel `push`, on tenterait de charger l'image dans le _Namespace_ officiel de CentOS.

Si utltérieuement, on construit une autre image avec un _Dockerfile_ qui contient les mêmes lignes – les mêmes instructions `RUN` – qu'une image précédemment "buildée", _Docker_ utilisera un système de cache pour toute instruction `RUN`.
Forcer Docker à recontruire chaque couches et éviter d'utiliser le cache des builds antérieurs
```sh
docker build myproject2/ -t myapp2 --no-cache
```


##### Le fichier `.dockerignore`

À l'instar du fichier `.gitignore` qui épargne l'envoi de certains dossiers et fichiers sur un repository distant, le fichier `.dockerignore` épargne le transfère de certains dossiers ou fichiers. Ce fichier est a placé au même niveau d'arborescence que le _Dockerfile_ et peut déjà contenir des références de ce genre
```
node_modules
vendor
.git
```


#### Remarques

Lors de la construction d'une image, tout le projet est transféré vers le _Docker Deamon_. Une arborescence équivalent à un fichier `.tar` envoyé au _Docker Engine_ à l'exception des fichiers listés dans le fichier `.dockerignore`.


### Rédaction

Pour tout projet, la première chose à faire est de créer un fichier `Dockerfile` à la racine du projet, et d'y définir différentes instructions. 

```Dockerfile
# Image de base à utiliser
FROM debian:9

# (optionel) - Informations sur l'éditeur, le type d'image, l'architecture, etc.
LABEL version="1.2" arch="x86-64" 

# (optionel) - Variables d'environnements typique applicative
ENV APP_TYPE="FRONTEND"
```

Ensuite, il faut définir les commandes à exécuter dans le conteneur. Il est possible d'inscrire plusieurs instructions `RUN`, mais chaque instruction rajoutera une _Layer_ et l'idée est de limiter leur nombre
```Dockerfile
RUN apt-get update -yq \
    && apt-get install curl gnupg -yq \
    && curl -sL https://deb.nodesource.com/setup_10.x | bash | 
    # etc.
```

Diverses instructions peuvent être définies selons les besoins
```dockerfile
# Copier un fichier ou un répertoire dans un autre répertoire
COPY entrypoint.sh

# Ajouter, copier ou télécharger des fichiers dans un certain dossier – notamment les sources d'une application. L'origine peut être à distance
ADD . /app/

# Répertoire de travail courant. Équivalent d'un `cd`, toute instruction suivante s'exécutera dans ce répertoire
WORKDIR /app

# Exposition du ports d'écoute, permet une meilleure compréhension du fichier
EXPOSE 2368

# Volumes utilisables
VOLUME /app/logs
# Ou plusieurs volume en une syntaxe
VOLUME [/app/bin /app/data]

# Utilisateur de référence pour l'exécution du conteneur
USER elo
```

Enfin, une commande finale à lancer lors de l’exécution du conteneur – généralement celle qui lance l'application – est à placer systématiquement à la fin pour une meilleure compréhension du fichier
```Dockerfile
# Commande de lancement de l'application
CMD npm run start
```

Il est également possible de définir un point d'entrée à l'intérieur du conteneur. À la création du conteneur, la première commande ou le premier script sera celui indiqué par cette instruction. Il contiendra la "logique" de démarrage de l'application. En général, c'est un script va orienter l'éxécution de l'application. Si l'instruction `CMD` existe, alors elle ne contiendra que des arguments pour `ENTRYPOINT`
```Dockerfile
# Valeur d'argument
CMD ['Hello']

# Cible du script à exécuter
ENTRYPOINT ["/entrypoint.sh"]
```


#### Exemple pratique

_Fichier `Dockerfile`_
```Dockerfile
FROM centos:7
LABEL version="1.5" arch="x86-64" 
ENV APP_TYPE="FRONTEND"
RUN yum install wget \
    && useradd -u 1000 -g 1000 elo
COPY entrypoint.sh
ADD archive.tar /data
WORKDIR /data
USER elo
CMD ["Bonjour"]
ENTRYPOINT ["/entrypoint.sh"]
```

_Script `entrypoint.sh`_
```sh
echo $* $(whoami) voici le contenu du répertoire $(pwd) 
```

_Commande de construction_
```sh
# Utiliser la valeur par défaut dans CMD – "Bonjour"
docker build . -t myapp3

# Écrassera la valeur dans CMD - "Hello"
docker build . -t myapp3 Hello 
```


#### Construction par étape

Exemple : une image _Alpine_ dans laquelle on ajoute un compilateur C et une librairie C
```sh
docker build -t myapp4:v1 . -f DockerfileV1
docker run myapp4:v1
```

Lorsqu'on observe l'image contruite à paprtir du [_DockerfileV1_](./_resources/DockerfileV1), on constate que l'image de `myapp4:v1` pèse ± 160 MB alors qu'_Alpine_ n'est que de 7 MB. Le binaire du programme C ne fait qu'un `print` à l'écran et sa taille est très petite. Le surpoid provient du compilateur _GCC_ et de la librairie `libc-dev` qui sont inclus dedans alors qu'il deviennent inutiles une fois la compilation effectuée.

L'idée est de regénérer une image sans la couche contenant le compilateur et la libraire. Pour ça il suffit de repartir d'une image _Alpine_ et de récupérer – `COPY` – le fichier compilé lors de la construction précédente

```sh
docker build -t myapp4:v2 . -f DockerfileV2
docker run myapp4:v2
```


### Distribution

#### Dépôt sur le _Docker Hub_

Le `Dockerfile` "pourrait" être partagée sur _GitHub_ ou _GitLab_, et ainsi permettre à chacun·e de reconstruire la même image sur son poste de travail. Mais le _Docker Hub_ personel permet justement l'échange d'images **déjà construites** et leurs synchronisations. 

Attribuer un nom et un tag à l'image qui correspond à son repository sur le Hub
```sh
docker tag my-image:latest elodiebayet/myimage:latest
```
Connexion à son _Docker Hub_
```sh
docker login
```
Envoi sur Docker Hub
```sh
docker push elodiebayet/myapp-docker-repo:latest
```


#### Analyser les images

D'un point de vue sécurité, les images ont besoin d'être contrôlées. [_Snyk_](https://snyk.io/) permet de scanner 10 images en local par mois gratuitement. _Snyk_ permet aussi de tester la vulnérabilité du code, et pour le cas d'un conteneur, on peut aller jusqu'à 100 tests par mois. Un compte payant permet de scanner automatiquement les images sur le _Docker Hub_ à chaque `docker push`.

Pour l'utiliser, il faut d'abord se connecter – `docker login`. Ensuite, il faut récupérer l'image `snyk/snyk` sur le _Docker Hub_.
```sh
# Voir la version et aussi télécharger l'image si elle est absente localement
docker scan --version

# Scanner une image
docker scan centos7:mywget

# Scanner un Dockerfile sans scanner son image de base
docker scan -f Dockerfile --exclude-base centos7:mywget

# Scanner en filtrant par degré de sévérité
docker scan --severity=high nginx:1.23

# Afficher les packages 
docker scan --dependancy-tree debian:buster | more
```


---


## Annexes

### Glossaire

**`stdin`**
Pour _standard input_, l'entrée standard, le cannal d'entrée qui porte le descripteur de fichier `0`. Par défaut, le clavier quand on lance une commande : la commande peut lire ce qu'on saisit.

**`stdout`**
Pour _standard output_, la sortie standard, le cannal de sortie qui porte le descripteur de fichier `1`. Ppar défaut, l'écran quand on lance une commande : l'écran affiche le résultat de la commande.

**`stderr`**
Pour _standard error_, le cannal du flux d'erreur qui porte le descripteur de fichier numéro `2`. Également l'écran quand on lance une commande : lorsque le programme lève une erreur, on redirige le flux d'information vers ce cannal.


### Pour en savoir plus

- [Démarrage : Workshop - Docker Docs](https://docs.docker.com/get-started/workshop/)
- [Manuels - Docker Docs](https://docs.docker.com/manuals/)
- [Guide complet Docker Compose - Towards Data Science](https://towardsdatascience.com/docker-compose-44a8112c850a)
- [Snyk](https://snyk.io/)

